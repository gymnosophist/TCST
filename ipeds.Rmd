---
title: Implementing the College Stress Test with data from the Integrated Postsecondary
  Education Data System (IPEDS)
author: "A. M. Leedom"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  pdf_document: default
  html_document:
    df_print: paged
---
# Introduction and Setup

This notebook covers the extraction of available IPEDS data with the aim of producing a Shiny app where users can explore the [college stress test](https://jhupbooks.press.jhu.edu/title/college-stress-test) as described by Zemsky et al. 

We'll use the IPEDS package from Jason Bryer to access the data. Note that users can download the IPEDS data for a given year (in .accdb format) [here](https://nces.ed.gov/ipeds/use-the-data/download-access-database)

```{r setup, include=FALSE}
# knitr::opts_chunk$set(tidy.opts = list(blank = FALSE, width.cutoff = 100))
options(width = 100)

### install if necessary. Note you may have to `brew install mdbtools` as well
# devtools::install_github('jbryer/ipeds', dependencies = T)

# load packages 
library(knitr)
library(ipeds)
library(tidyverse)
library(hrbrthemes)
library(stringr)
# set download directory if desired
getOption('ipeds.download.dir')
```

It should be noted that data files downloaded to the package directory will be deleted for each new R or `ipeds` installation. The default location to download data files can be changed by specifying the `ipeds.download.dir` system property using the `options` command. I've set it to a folder within my working directory. The data will be uploaded to GitHub as part of the finished product. 

```{r download_directory_set, eval = T}
# set the directory to our project folder
ipeds_dir <- paste0(getwd(), "/ipeds_data")
options('ipeds.download.dir' = ipeds_dir)

# see if the option has been set properly
getOption('ipeds.download.dir')
```

# Identifying and downloading available data

The `download_ipeds` function will download all data files for the specified year(s). The `available_ipeds` function can tell us which years are available for download. The data files are generally around 50MB. Note that if we call `download_ipeds` with a blank year parameter we get the latest available survey. Let's see what the latest available surveys are. 

```{r available ipeds}
available_ipeds() %>% tail(10) %>% as_tibble()
```

From the documentation: 


>The following parameters are available for the `download_ipeds` function:

>* `year` - the years to download. IPEDS organizes data into academic years. The year specified is the ending year. For example, `year = 2018` would download the database for the 2017-18 academic year.
* `dir` - the directory to download the IPEDS data files to. This will override the `ipeds.download.dir` system property.
* `useProvisional` - indicates whether a provisional database (if available) be downloaded if the final version is not.
* `cleanup` - indicates whether the function should delete any intermediate files downloaded (e.g. zip files) or extracted (e.g. accdb files).

>The `available_ipeds` function returns a `data.frame` with a summary of the available IPEDS data files along with the download status of those files.


Let's download the latest available `provisional` surveys, from 2018-19. 

```{r download ipeds, message=FALSE, eval = F}
download_ipeds(2019, cleanup = T, dir = 'ipeds_data')
```

In the repo, I've added the necessary data. If you want to replicate the rest of the analysis, you'll need to download the data for the last **7 years**. 

# Data Dictionaries

From the documentation:


```{r}
load_ipeds(2019) %>% names
```


>NCES provides data dictionaries with the IPEDS data. There are two main data frames that summarize the data that is available in any year, one describes all the data tables available and the other describes the variables within a data table. Both these data dictionaries are available using the `ipeds_help` function. 

>The `table` parameter can be either the short `surveyID` from the `data(surveys)` data frame (see Appendix A), or the full table name in the result above. For example, `ipeds_help('HD2017', year = 2018)` and `ipeds_help('HD', year = 2018)` will return the same data frame. The advantage of the latter approach is that specific surveys can be retrieved across years. That is, `ipeds_help('HD')` will always return the directory information data frame for the most current IPEDS database.


The dictionaries are huge. Let's see what we have. For example, we've downloaded the 2019 data. One of the metrics we look at is the `number of first-year students`. That information should be available in the `IC` (Institutional Characteristics) table. Let's see what we have from 2019. 

```{r}
View(ipeds_help('IC', 2019)) # view the data dictionary in another window 

ipeds_help('IC', 2019) %>% as_tibble() %>% head() # preview 
```


# Getting Data

 `load_ipeds`  will return a list with all the data tables for the given year.

```{r ipeds 2019 names}
ipeds_2019 <- load_ipeds(2019)

names(ipeds_2019)
```

So these are the surveys available to us for the 2019 data. 

# Overview of the data and clustering

The TCST authors break down five classes of institutions. Their classification is based on graduation rates. 

Let's see if we can replicate their findings using k-means clustering and two variables, graduation rate and market price (which we will use later as a component of the stress test).

We'll only include four-year colleges and data from 2019 in this analysis to keep things clean(ish). 

```{r get graduation rate and market price for k-means}
gr.2019 <- ipeds_survey("GR200_18", 2019)
hd.2019 <- ipeds_survey('HD', 2019) %>% select(c(UNITID, ICLEVEL)) # for filtering
gr.2019 <- # get graduation rate for four-year colleges 
    gr.2019 %>% select(c(UNITID, BAGR150)) %>% left_join(hd.2019) %>% filter(ICLEVEL == 1) 

### get price data 

mp.2019 <- ipeds_survey("SFA1718_P2", 2019) %>% 
    select(c(UNITID, NPIST2, NPGRN2)) %>% 
    transmute(UNITID = UNITID, 
              year = 2019, 
              avg_net_price = ifelse(!is.na(NPIST2), NPIST2, NPGRN2))

combined <- 
    gr.2019 %>% 
    left_join(mp.2019, by = 'UNITID')

### perform the clustering

library(factoextra) # for plotting 



# extract and scale data 
# we need graduation rate ()

```
```{r run and visualize clusters}
combined.scaled <- combined %>% 
    mutate(graduation_rate = scale(BAGR150), 
           avg_net_price = scale(avg_net_price)) %>% drop_na() # drop NaNs for clustering

combined.km <- kmeans(combined.scaled[, c('graduation_rate', 'avg_net_price')], centers = 5, nstart = 20)

cluster_viz <- fviz_cluster(combined.km, data = combined.scaled[, c('graduation_rate', 'avg_net_price')],
             palette = c("#2E9FDF", "#00AFBB", "#E7B800", "#f5427e", "#138211"), 
             geom = "point",
             ellipse.type = "convex", 
             ggtheme = theme_bw()
             )
cluster_viz + 
    ggtitle("Cluster Analysis of Four-Year Colleges and Universities") + 
    xlab("Six Year Graduation Rate (z-score)") + 
    ylab("Average Net Price (z-score)") + 
    scale_color_manual(name = 'Institutional Level', 
                       labels = c(
                           "Medallion", # Good Buy
                                   "Name Brand", # Good Opportunity
                                   "Good Buy", # Convenience
                                   "Good Opportunity", # Medallion
                                   "Convenience" # Name Brand
                           ),
                       values = c(
                           "#2E9FDF", 
                           "#00AFBB",
                           "#E7B800",
                           "#f5427e",
                           "#138211"
                       )
                       ) +
    theme(plot.title = element_text(hjust = .25))
```


```{r}
wss <- 0 

for (i in 1:15) {
  km.out <- kmeans(combined.scaled[, c('graduation_rate', 'avg_net_price')], centers = i, nstart = 20)
  # Save total within sum of squares to wss variable
  wss[i] <- km.out$tot.withinss
}

plot(1:15, wss, type = "b", 
     xlab = "Number of Clusters", 
     ylab = "Within groups sum of squares")


```
```{r}
# how large is each cluster?
table(combined.km$cluster) / sum(table(combined.km$cluster))
```

# 1. Enrollment data

Let's look at the first component of the stress test, first-year enrollment. 

Our aim here is to extract for a given college / university a time series looking at the percent change in freshman enrollment over a suitable time period. 

We then fit a linear regression line to the data, and project the line forward in time to see whether it will cross the 'warning' or 'alert' levels, which we establish by looking at the 25th and 10th percentiles of all the colleges / universities in a given class. 

If that doesn't make sense, it should when we're through this first example. 


# Getting first-year enrollment

The `ipeds_survey` function will load a specific data table for the given year. 

Looks like what we want is in the `DRVEF` table (commonly DeRiVed statistics from Fall Enrollment). We want the `EFUG1ST` variable: 

>"First-time degree/certificate seeking undergraduate men and women enrolled for credit in the fall of the academic year. 

>First-time student (undergraduate)  A student who has no prior postsecondary experience (except as noted below) attending any institution for the first time at the undergraduate level. This includes students enrolled in academic or occupational programs. It also includes students enrolled in the fall term who attended college for the first time in the prior summer term, and students who entered with advanced standing (college credits earned before graduation from high school).  

>Degree/certificate-seeking students  Students enrolled in courses for credit and recognized by the institution as seeking a degree, certificate, or other formal award. High school students also enrolled in postsecondary courses for credit are not considered degree/certificate-seeking 
Undergraduate - A student enrolled in a 4- or 5-year bachelor's degree program, an associate's degree program, or a vocational or technical program below the baccalaureate. 

>CREDIT - Recognition of attendance or performance in an instructional activity (course or program) that can be applied by a recipient toward the requirements for a degree, diploma, certificate, or other formal award. 

>NOTE: Enrollment reported is of the institution's official fall reporting date or October 15."

We'll also include the `EF` table, in case we want to look at fall enrollment more generally. 

```{r ipeds_survey, eval=T}

# load some data 

ipeds.ef <- ipeds_survey('EF', 2019)
ipeds.drvef_2019 <- ipeds_survey('DRVEF2018', 2019)
ipeds.hd <- ipeds_survey('HD', 2019) # includes identifying information for each college 
```

```{r ipeds fall enrollment, 2019}

# let's take a quick look at enrollment data

ipeds.ef %>% select(-UNITID) %>% boxplot # quick check on the distribution

```


```{r explore DRVEF}
# check missing values 
ipeds.drvef_2019 %>% select(c(UNITID, EFUG1ST)) %>% purrr::map_dbl(~sum(is.na(.x))) 

ipeds.drvef_2019 %>% select(c(EFUG1SFT)) %>% summary
```

# Scaling up with first-year enrollment

Ok, let's go ahead and collect and assemble the rest of the data. We'll go ahead and download all the files for now, then delete what we don't need later. 
(Really this will mean locating the data we want and saving CSVs when we're done with it.)

```{r download additional years of ipeds data, message = F}
download_ipeds(2013, dir = 'ipeds_data', cleanup = , force = FALSE)
```

Note that not all of the urls were coded properly by the `download_ipeds` function. After some debugging, I downloaded the .zip archives manually, then continued with conversion to .RDA with this function. 

Now let's do a double check that we have the data available. 

```{r double check we have the necessary data}
available_ipeds() %>% filter(!is.na(download_date))
```

We should have data back to 2010 now, which gives us a good time horizon for conducting our analysis. `download_ipeds` saves the data as an RDA file, which is much smaller than the access databases IPEDS files come in. 

Let's get the first-year enrollment data. We'll also divide our institutions into classes like the authors of TCST. 

```{r generate enrollment time series}
extract_enrollment <- function(year){ 
    #' extract enrollment data from IPEDS surveys in a given year 
    ipeds <- load_ipeds(year)
    survey_string <- paste0("DRVEF", year - 1)
    print(survey_string)
    survey <- ipeds::ipeds_survey(survey_string, year = year)
    survey <-  survey %>% 
        select(c(UNITID, EFUG1ST)) %>% 
        mutate(year = year)
    }


data_list = list()

for (year in seq(2012,2019)){
    data_list$year = year 
    data_list[[year]] <- extract_enrollment(year)
}

enrollment_df <-  do.call(rbind, data_list)

```

Now we check to see if we've created our panel correctly: 

```{r check panel data}

enrollment_df %>% arrange(`UNITID`, year)%>% 
    mutate(UNITID = as.character(UNITID)) %>% 
    as_tibble %>% 
    filter(UNITID == 100654) %>% 
    mutate(pct_change = EFUG1ST /first(EFUG1ST) - 1) %>%
    head

```

Ok looks reasonable. Let's choose a random unit_id for testing 

```{r plot test case, message = F}
set.seed(123)
test <- sample(enrollment_df[,'UNITID'], 1) # American College of Hairstyling-Des Moines

enrollment_df %>% filter(UNITID == test) %>% ggplot(aes(x = year, y = EFUG1ST)) + 
    geom_line(aes(y = EFUG1ST, x = year), lty = 1, lwd = .75) + 
    ylab('New Undergraduate Enrollment') + 
    xlab('Year') +
    ggtitle("New First-Time First-Year Enrollment at a Midwestern Vocational School") + 
    geom_point() + 
    geom_smooth(aes(x = year, y = EFUG1ST), method = 'lm', se = F, color = 'black', lty = 2, lwd = .25) + 
    theme_bw() + 
    theme(plot.title = element_text(hjust = .5))
```
```{r saving our enrollment_df}
# write.csv(enrollment_df, 'enrollment_df.csv')
```


```{r index change in enrollment}
# To calculate the stress test, we need to index the change in enrollment starts to the first year in our dataset 

enrollment_panel_indexed <- 
    enrollment_df %>% # changed from enrollment_panel
    group_by(UNITID) %>% 
    mutate(index_enrollment_change = (EFUG1ST / first(EFUG1ST) - 1 * 100) +  100) %>% 
    mutate(index_enrollment_change = index_enrollment_change * 100) %>%
    ungroup() 
enrollment_panel_indexed
```

# Establish alert and warning levels for first-year matriculation

Our next task is to determine the distribution of enrollment numbers across our sample and determine "alert" and "warning" values from that. 

To compare apples to apples and replicate what TCST's authors did, we need to use the IC table to classify our sample into distinct groups. The four groups are: 

- Public, four-year institutions; 
- Private four-year; 
- Two-year; 
- Four-year for profit. 

We can use the `HD` survey to identify those classes.

```{r generate panel data with descriptive characteristics}

enrollment_panel <- 
    ipeds.hd %>% select(c(UNITID, INSTNM, ICLEVEL, CONTROL)) %>% right_join(enrollment_df, by = 'UNITID')

### Now we split-apply-combine to generate our distributions.  

enrollment_panel %>% 
    filter(ICLEVEL == 1, 
           year == 2018, 
           EFUG1ST > 0) %>%
    ggplot(aes(x = EFUG1ST)) + 
    geom_histogram(bins = 50) + 
    theme_bw() + 
    xlab("New enrolled First-Year Students") + 
    ylab('Count') + 
    ggtitle("First time first-year students enrolled at four-year degree-granting institutions, 2018")
    
```

Looks like we have a fractal enrollment pattern among these schools. Most schools have enrollment classes that are well under ~1,000 students (median 219, mean 636.5). 

We can also now compute the `warning` and `alert` values based on the distribution of fall enrollment changes. 

The authors of TCST establish the `warning` and `alert` thresholds thus: 

>The alert threshold is set at the 20th percentile of the distribution of the component in question; the warning boundary is the value at the lowest 10th percentile (48)

Let's look at the distribution of percentage change in `EFUG1ST` over our time period (2012 - 2019). (I've indexed the values to 100, so we should see percentage changes in whole numbers.)

```{r}
enrollment_panel_indexed %>% filter(CONTROL == 1)
```
```{r delete this cell}
enrollment_change.public_fy <- enrollment_panel_indexed  %>% 
    filter(CONTROL == 1, # public, four-year
           ICLEVEL == 1) %>% 
    group_by(UNITID) %>% 
    mutate(overall_pct_change = last(index_enrollment_change) - 100) %>% 
    select(c(UNITID, overall_pct_change)) %>%
    right_join(unique_schools, by = 'UNITID') %>% 
    drop_na %>% 
    unique
```


```{r establish alert and warning levels for freshman enrollment, warning = F} 
# get list of IDs for joining

unique_schools <- unique(enrollment_panel$UNITID)
unique_schools <- unique_schools %>% as_tibble %>% set_names('UNITID')


enrollment_change.public_fy <- enrollment_panel_indexed  %>% 
    filter(CONTROL == 1, # public, four-year
           ICLEVEL == 1) %>% 
    group_by(UNITID) %>% 
    mutate(overall_pct_change = last(index_enrollment_change) - 100) %>% 
    select(c(UNITID, overall_pct_change)) %>%
    right_join(unique_schools, by = 'UNITID') %>% 
    drop_na %>% 
    unique

print(quantile(enrollment_change.public_fy$overall_pct_change, c(.1, .25)))

enrollment_change.public_fy %>% 
    ggplot(aes(x = overall_pct_change)) + 
    geom_histogram(bins = 100, alpha = .8) + 
    xlim(-200, 200) + 
    theme_bw() + 
    geom_vline(xintercept = quantile(enrollment_change.public_fy$overall_pct_change, .1), lty = 2, col = 'red') + 
    geom_vline(xintercept = quantile(enrollment_change.public_fy$overall_pct_change, .25), lty = 2, col = 'orange') + 
    ggtitle("Distribution of Percentage Change in Freshman Enrollment at Public Four-Year Institutions") + 
    ylab("Number of Schools") + 
    xlab("Percentage Change in FY Enrollment, 2012 - 2019") + 
    theme(plot.title = element_text(hjust = .7))
```

And we can look at all four-year colleges in the same way: 

```{r enrollment change, all four-year schools}
enrollment_change.fy <- enrollment_panel_indexed  %>% 
    filter(ICLEVEL == 1, 
           index_enrollment_change > 0) %>% #only grab four-year schools
    group_by(UNITID) %>% 
    mutate(overall_pct_change = last(index_enrollment_change) - 100) %>% 
    select(c(UNITID, overall_pct_change)) %>%
    right_join(unique_schools, by = 'UNITID') %>% 
    drop_na %>% 
    unique

print(quantile(enrollment_change.fy$overall_pct_change, c(.1, .25)))

enrollment_change.fy %>% 
    ggplot(aes(x = overall_pct_change)) + 
    geom_histogram(bins = 100, alpha = .8) + 
    xlim(-200, 200) + 
    theme_bw() + 
    geom_vline(xintercept = quantile(enrollment_change.public_fy$overall_pct_change, .1), lty = 2, col = 'red') + 
    geom_vline(xintercept = quantile(enrollment_change.public_fy$overall_pct_change, .25), lty = 2, col = 'orange') + 
    ggtitle("Distribution of Percentage Change in Freshman Enrollment at Four-Year Institutions") + 
    ylab("Number of Schools") + 
    xlab("Percentage Change in FY Enrollment, 2012 - 2019") + 
    theme(plot.title = element_text(hjust = .7))
```


# Retention Rates

Now we can look at our second indicator, freshman retention rate. 

We find this in the `RET_PCF` again in the `EF` (fall enrollment) table. 

```{r get freshman retention rate}
extract_retention <- function(year){
    #' extract retention data from IPEDS surveys in a given year 
    ipeds <- load_ipeds(year)
    survey_string <- paste0("EF", year - 1, "D")
    print(survey_string)
    survey <- ipeds::ipeds_survey(survey_string, year = year)
    survey <-  survey %>% 
        select(c(UNITID, RET.PCF)) %>% 
        mutate(year = year)
}

retention_df_list = list()

for (year in seq(2012,2019)){
    retention_df_list$year = year 
    retention_df_list[[year]] <- extract_retention(year)
}

retention_df <-  do.call(rbind, retention_df_list)
retention_df %>% head
```

```{r make retention panel data}
retention_df <- retention_df %>% 
    mutate(UNITID = as.integer(UNITID)) 
retention_panel <- 
    ipeds.hd %>% select(c(UNITID, INSTNM, ICLEVEL, CONTROL)) %>% right_join(retention_df, by = 'UNITID')
retention_panel %>% mutate(RET.PCF = as.double(RET.PCF)) %>% head(10)
```

Retention rates do not need to be indexed like new first-year enrollment, our first indicator.

# 2. Financial Measures

# Ratio of Endowment to Expenses 

Our next measure is a ratio of endowment to expenses. 

This metric measures an institution's ability to meet its operating needs through tuition or the endowment, and whether an institution's costs have gotten out of control. 

Here we need to collect data from two IPEDS surveys to create our panel. We use the `F_F2` table for total expense data and endowment asset value. 

```{r check names}
ipeds_2019 <- load_ipeds(2019)
ipeds_2019 %>% names
```

```{r get expense ratio df}

create_expense_ratio <- function(year){
    #' extract endowment:expenses ratio for a given IPEDS year 
    
    year_two <- str_sub(toString(year - 1), -2, -1)
    year_one <- str_sub(toString(year - 2), -2, -1)
    
    # get expense data 
    
    finance_string = paste0("F",year_one, year_two, "_F2")
    finance <- ipeds_survey(finance_string, year) %>% 
        select(c(UNITID, F2B02, F2H01)) %>% 
        mutate(year = year, 
               `endowment:expense` = F2H01 / F2B02)

}

## now create panel 

ratio_df_list = list()

for (year in seq(2012,2019)){
    ratio_df_list$year = year 
    ratio_df_list[[year]] <- create_expense_ratio(year)
}

ratio_df <-  do.call(rbind, ratio_df_list)
ratio_df %>% head

```

We now have three of our four indicators! Sure we may have some additional filtering to do, but we've almost got the necessary components for our stress test. 

# Market Price 

This is the trickiest one. The Department of Education has undertaken a major effort to make college prices transparent. 

This has included a requirement to disclose the net price of attendance at each post-secondary institution.

Market prices are among the most discussed indicators in TCST. The market price is an institution's tuition fees less institution-granted financial aid. 

Institutions that are likely to experience distress in the near future (or are already experiencing it) are often marked by lower and lower market prices--essentially putting their product (higher education) on sale. 

This information is in the `SFA{YY}_P2` table. 

```{r extract market price data, warning=F}
extract_market_price <- function(year){
    year_two <- str_sub(toString(year - 1), -2, -1)
    year_one <- str_sub(toString(year - 2), -2, -1)
    
    survey_string <- paste0("SFA", year_one, year_two, "_P2")
    survey <- ipeds_survey(survey_string, year) %>% 
        select(c(UNITID, NPIST2, NPGRN2)) %>% 
        transmute(UNITID = UNITID, 
                  year = year, 
                  avg_net_price = ifelse(!is.na(NPIST2), NPIST2, NPGRN2))
    survey
}

extract_market_price(2018) %>% ggplot(aes(x = avg_net_price)) + 
    geom_histogram(bins = 50, alpha = .8) + 
    theme_bw() + 
    ylab("Number of Institutions") + 
    xlab("Average Net Price ($)") + 
    ggtitle("Average Net Price of Attendance, 2017-2018") 
    
```
Let's now generate our market price data frames just as we have before, and then join everything together. 

```{r get net price df}
price_list = list()

for (year in seq(2012,2019)){
    price_list$year = year 
    price_list[[year]] <- extract_market_price(year)
}

price_df <-  do.call(rbind, price_list)

```
```{r creatae master df}
master <- 
    enrollment_panel_indexed %>% 
    left_join(price_df, by = c('UNITID', 'year')) %>% 
    left_join(retention_panel %>% select(c(UNITID, year, RET.PCF)), by = c('UNITID', 'year')) %>% 
    left_join(ratio_df %>% select(c(UNITID, year, `endowment:expense`)), by = c("UNITID", "year"))

master %>% write.csv("master_df.csv")
```

# Get appropriations data 

We need to get appropriations data for public colleges and universities. 

```{r get state appropriations}

## state appropriations for public colleges 
extract_appropriations <- function(year){ 
    #' extract enrollment data from IPEDS surveys in a given year 
    ipeds <- load_ipeds(year)
    year_two <- str_sub(toString(year - 1), -2, -1)
    year_one <- str_sub(toString(year - 2), -2, -1)
    survey_string <- paste0("F", year_one, year_two, "_F2")
    survey <- ipeds_survey(survey_string, year) %>% 
        select(c(UNITID, F2D02, F2D03, F2D04)) %>% 
        transmute(UNITID = UNITID, 
                  year = year, 
                  total_appropriations = rowsum.data.frame(c(F2D02, F2D03, F2D04)))
    survey
}
    

appropriations_list = list()

for (year in seq(2012,2019)){
    appropriations_list$year = year 
    appropriations_list[[year]] <- extract_appropriations(year)
}

appropriations_df <-  do.call(rbind, appropriations_list)

appropriations_df %>% head(25)
```

```{r}
appropriations_df %>% head(25)
```



# Wrapping up

We should now have just about everything to build our app.

The code for the app is also available in this repo, [link](link) 

# Session info 

```{r session info}
sessionInfo()
```



---

# Appendix A: Surveys Documentation

From the original IPEDS package documentation

>The following tables contains all the surveys listed in the `data(surveys)` data frame. The `surveyID` variable can be used with the `ipeds_survey` and `ipeds_help` functions. Using this ID allows you to reference an IPEDS survey data table without a specific year. This is the preferred method for getting survey data, however there may be data tables in a particular release that are not references in this table. You can get those by specifying the full table name as referenced in the results of the `ipeds_help()` function.

```{r surveys, echo=FALSE, results='asis'}
data(surveys)
knitr::kable(surveys[,1:3], row.names = FALSE)
```

